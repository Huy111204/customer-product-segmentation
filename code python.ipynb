{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "z29a2BUcre5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.neighbors import NearestNeighbors"
      ],
      "metadata": {
        "id": "Q9ESlb1lQiVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNRvGQcPm3Zx"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/BI/Global_Superstore2.csv', encoding='latin1')\n",
        "df.head(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "L8Ru-S4WN-pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "UCPafDLEouA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(\"Postal Code\",axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "q3HE2I8iH3TG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_duplicates(df):\n",
        "    print(\"##################### Duplicates #####################\")\n",
        "    print(df.duplicated().sum())\n",
        "check_duplicates(df)"
      ],
      "metadata": {
        "id": "FledW7_jNudT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# show the missing values in dataset with ratio\n",
        "def missing_values_tabl(df):\n",
        "\n",
        "    na_columns = [col for col in df.columns if df[col].isnull().sum() > 0]\n",
        "    n_miss = df[na_columns].isnull().sum().sort_values(ascending=False)\n",
        "    ratio = (df[na_columns].isnull().sum() / df.shape[0] * 100).sort_values(ascending=False)\n",
        "    missing_df = pd.concat([n_miss, np.round(ratio,2)], axis=1, keys=['n_miss', 'ratio'])\n",
        "    missing_df = pd.DataFrame(missing_df)\n",
        "    return missing_df\n",
        "\n",
        "missing_values_tabl(df)"
      ],
      "metadata": {
        "id": "nUgtV2IaN0Pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting object to datetime\n",
        "df['Order Date'] = pd.to_datetime(df['Order Date'], dayfirst=True, errors='coerce')\n",
        "df['Ship Date']  = pd.to_datetime(df['Ship Date'],  dayfirst=True, errors='coerce')"
      ],
      "metadata": {
        "id": "BkZRyGDrsILo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating new features\n",
        "df[\"order year\"]=df[\"Order Date\"].dt.year\n",
        "df[\"order_month\"]=df[\"Order Date\"].dt.month\n",
        "df[\"ship year\"]=df[\"Ship Date\"].dt.year\n",
        "df[\"ship_month\"]=df[\"Ship Date\"].dt.month\n",
        "# unit price\n",
        "df[\"unit_price\"]=df[\"Sales\"]/df[\"Quantity\"]\n",
        "# rename columns\n",
        "df.rename(columns={\"Order Date\":\"order_date\",\"Ship Date\":\"ship_date\",\"Order Priority\":\"order_priority\"},inplace=True)"
      ],
      "metadata": {
        "id": "PvNvLNm9GRBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **K-Means Clustering ( Phân cụm khách hàng ) **"
      ],
      "metadata": {
        "id": "-RVY-9fnMMMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tính toán RFM cho phân cụm\n",
        "rfm = df.groupby('Customer ID').agg({\n",
        "    'order_date': lambda x: (df['order_date'].max() - x.max()).days,\n",
        "    'Order ID': 'nunique',\n",
        "    'Sales': 'sum'\n",
        "}).reset_index()\n",
        "rfm.columns = ['Customer ID', 'Recency', 'Frequency', 'Monetary']"
      ],
      "metadata": {
        "id": "NvzGOQtJJZ7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kiểm tra xem rfm có NaN không\n",
        "print(rfm[['Recency','Frequency','Monetary']].isnull().sum())"
      ],
      "metadata": {
        "id": "bDqKgb3bHIJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo DataFrame sạch: drop những dòng có Recency NaN\n",
        "rfm = rfm.dropna(subset=['Recency','Frequency','Monetary']).reset_index(drop=True)\n",
        "# Chuẩn hóa dữ liệu khách hàng\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "rfm_scaled = scaler.fit_transform(rfm[['Recency','Frequency','Monetary']])"
      ],
      "metadata": {
        "id": "egitKjJaLJnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tính SSE cho Elbow Method\n",
        "sse = []\n",
        "for k in range(1, 11):\n",
        "    km = KMeans(n_clusters=k, random_state=1)\n",
        "    km.fit(rfm_scaled)\n",
        "    sse.append(km.inertia_)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(range(1,11), sse, 'o-')\n",
        "plt.xlabel('k clusters')\n",
        "plt.ylabel('SSE')\n",
        "plt.title('Elbow method cho RFM')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "855sdA3jPpdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sil_scores = []\n",
        "for k in range(2,11):\n",
        "    km = KMeans(n_clusters=k, random_state=1).fit(rfm_scaled)\n",
        "    sil_scores.append(silhouette_score(rfm_scaled, km.labels_))\n",
        "plt.figure()\n",
        "plt.plot(range(2,11), sil_scores, 'o-')\n",
        "plt.xlabel('k clusters')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Analysis cho RFM')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "F8SUc162H-mP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, (inertia, sil) in enumerate(zip(sse[1:], sil_scores), start=2):\n",
        "    print(f\"k={k}: inertia={inertia:.2f}, silhouette={sil:.3f}\")"
      ],
      "metadata": {
        "id": "YbjYzeQ2IGCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Áp dụng KMeans với k tối ưu\n",
        "k_optimal = 3\n",
        "kmeans = KMeans(n_clusters=k_optimal, random_state=1)\n",
        "rfm['Cluster'] = kmeans.fit_predict(rfm_scaled)"
      ],
      "metadata": {
        "id": "gEvcwr44PuhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Phân tích kết quả KMeans\n",
        "print(\"Silhouette Score KMeans:\", silhouette_score(rfm_scaled, rfm['Cluster']))"
      ],
      "metadata": {
        "id": "X6SeFaGpIpPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Đếm số lượng khách hàng trong mỗi cụm\n",
        "counts = rfm['Cluster'].value_counts().sort_index()\n",
        "# Phân tích kết quả trung bình các đặc trưng theo cụm\n",
        "cluster_summary = rfm.groupby('Cluster')[['Recency', 'Frequency', 'Monetary']].mean().round(2)\n",
        "print(\"\\n Trung bình RFM theo từng cụm:\\n\", cluster_summary)\n"
      ],
      "metadata": {
        "id": "rckqMor7LDXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vẽ biểu đồ trực quan\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "pcs = pca.fit_transform(rfm_scaled)\n",
        "df_pca = pd.DataFrame(pcs, columns=['PC1','PC2'])\n",
        "df_pca['Cluster'] = rfm['Cluster']\n",
        "sns.scatterplot(data=df_pca, x='PC1', y='PC2', hue='Cluster', palette='tab10')\n",
        "plt.title(\"RFM clusters in 2D PCA space\")\n",
        "plt.show()\n",
        "\n",
        "sns.pairplot(rfm, hue='Cluster', vars=['Recency', 'Frequency', 'Monetary'], palette='tab10')\n",
        "plt.suptitle(\"Phân cụm khách hàng theo RFM\", y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Wg2LLiaURrhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **K-Means Clustering ( Phân cụm sản phẩm ) **"
      ],
      "metadata": {
        "id": "oHtWwXZcKLRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo feature cho sản phẩm\n",
        "product_df = (\n",
        "    df.groupby('Product Name')\n",
        "      .agg(\n",
        "         OrderCount   = ('Order ID', 'nunique'),\n",
        "         TotalQuantity= ('Quantity', 'sum'),\n",
        "         TotalSales   = ('Sales', 'sum'),\n",
        "         TotalProfit  = ('Profit', 'sum'),\n",
        "         AvgPrice     = ('unit_price', 'mean')\n",
        "      )\n",
        "      .reset_index()\n",
        ")\n"
      ],
      "metadata": {
        "id": "mScGAvqkTR_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chuẩn hóa dữ liệu của sản phẩm\n",
        "X = product_df[['OrderCount', 'TotalQuantity', 'TotalSales', 'TotalProfit', 'AvgPrice']]\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "dI8xjl9-KXZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tính SSE cho Elbow Method\n",
        "sse = []\n",
        "K_range = range(1, 11)\n",
        "for k in K_range:\n",
        "    km = KMeans(n_clusters=k, random_state=42)\n",
        "    km.fit(X_scaled)\n",
        "    sse.append(km.inertia_)\n",
        "\n",
        "# Vẽ Elbow plot\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(K_range, sse, 'o-', linewidth=2)\n",
        "plt.xlabel('Số cụm k')\n",
        "plt.ylabel('SSE (Inertia)')\n",
        "plt.title('Elbow Method – Sản phẩm')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bnrWjNRAUTxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Áp dụng K-means với K tối ưu\n",
        "k_opt_p = 3\n",
        "product_df['KMeans_Cluster'] = KMeans(n_clusters=k_opt_p, random_state=42).fit_predict(X)\n",
        "print(\"Silhouette Score (products):\", silhouette_score(X, product_df['KMeans_Cluster']))"
      ],
      "metadata": {
        "id": "ioWOR1H1J2cF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Thống kê trung bình theo cụm\n",
        "cluster_summary = product_df.groupby('KMeans_Cluster')[['OrderCount', 'TotalQuantity', 'TotalSales', 'TotalProfit', 'AvgPrice']].mean().round(2)\n",
        "print(\" Trung bình theo cụm sản phẩm:\")\n",
        "print(cluster_summary)"
      ],
      "metadata": {
        "id": "dWg5L8awUZ10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Đếm số lượng sản phẩm trong mỗi cụm\n",
        "product_df['KMeans_Cluster'].value_counts().sort_index()\n"
      ],
      "metadata": {
        "id": "tQNUjyRKWNt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA 2D scatter\n",
        "pca = PCA(n_components=2)\n",
        "pcs = pca.fit_transform(X_scaled)\n",
        "df_pca = pd.DataFrame(pcs, columns=['PC1','PC2'])\n",
        "df_pca['KMeans_Cluster'] = product_df['KMeans_Cluster']\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.scatterplot(data=df_pca, x='PC1', y='PC2', hue='KMeans_Cluster', palette='tab10', s=50)\n",
        "plt.title(\"PCA projection of Product Clusters\")\n",
        "plt.show()\n",
        "\n",
        "# Boxplot TotalProfit theo cụm\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.boxplot(data=product_df, x='KMeans_Cluster', y='TotalProfit', palette='Set2')\n",
        "plt.title(\"Phân phối TotalProfit theo cụm sản phẩm\")\n",
        "plt.show()\n",
        "\n",
        "# Pairplot (tuỳ chọn)\n",
        "sns.pairplot(product_df, hue='KMeans_Cluster', vars=X, palette='tab10')\n",
        "plt.suptitle(\"Pairplot - Product Clusters\", y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R0D-aZt2UmGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DBSCAN**"
      ],
      "metadata": {
        "id": "lOOFZMZECfAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score\n",
        "# Áp dụng DBSCAN\n",
        "dbscan = DBSCAN(eps=0.33, min_samples=4)\n",
        "rfm['DBSCAN_Cluster'] = dbscan.fit_predict(rfm_scaled)"
      ],
      "metadata": {
        "id": "SLC2N9gZBO0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Đếm số cụm và nhiễu (-1 là noise)\n",
        "print(\"Số lượng cụm:\", len(rfm['DBSCAN_Cluster'].unique()) - (1 if -1 in rfm['DBSCAN_Cluster'].unique() else 0))\n",
        "print(\"Số khách hàng nhiễu (noise):\", (rfm['DBSCAN_Cluster'] == -1).sum())"
      ],
      "metadata": {
        "id": "BUGEQRbGCoNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tính silhouette score (chỉ tính nếu có hơn 1 cụm)\n",
        "n_clusters = len(set(rfm['DBSCAN_Cluster'])) - (1 if -1 in rfm['DBSCAN_Cluster'].values else 0)\n",
        "if n_clusters > 1:\n",
        "    score = silhouette_score(rfm_scaled, rfm['DBSCAN_Cluster'])\n",
        "    print(f\"Silhouette Score: {score:.3f}\")\n",
        "else:\n",
        "    print(\"Không thể tính Silhouette Score (chỉ có 1 cụm hoặc toàn outlier).\")"
      ],
      "metadata": {
        "id": "gMv2ZhWZCoa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "components = pca.fit_transform(rfm_scaled)\n",
        "rfm['PCA1'] = components[:,0]\n",
        "rfm['PCA2'] = components[:,1]\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.scatterplot(data=rfm, x='PCA1', y='PCA2', hue='DBSCAN_Cluster', palette='Set1', legend='full')\n",
        "plt.title(\"Phân cụm khách hàng bằng DBSCAN (PCA 2D)\")\n",
        "plt.legend(title='Cụm')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SLefOCFNCtwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "dbscan = DBSCAN(eps=2.5, min_samples=4)\n",
        "product_df['DBSCAN_Cluster'] = dbscan.fit_predict(X_scaled)\n",
        "\n",
        "n_clusters = len(set(product_df['DBSCAN_Cluster'])) - (1 if -1 in product_df['DBSCAN_Cluster'] else 0)\n",
        "n_noise = sum(product_df['DBSCAN_Cluster'] == -1)\n",
        "\n",
        "print(\"Số cụm:\", n_clusters)\n",
        "print(\"Số sản phẩm nhiễu (noise):\", n_noise)\n",
        "\n",
        "# Tính Silhouette Score nếu đủ cụm\n",
        "if n_clusters > 1:\n",
        "    score = silhouette_score(X_scaled[product_df['DBSCAN_Cluster'] != -1],\n",
        "                             product_df['DBSCAN_Cluster'][product_df['DBSCAN_Cluster'] != -1])\n",
        "    print(f\"Silhouette Score: {score:.3f}\")\n",
        "else:\n",
        "    print(\"Không thể tính Silhouette Score.\")\n"
      ],
      "metadata": {
        "id": "_JNDgU7WQ4DN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "product_components = pca.fit_transform(X_scaled)\n",
        "\n",
        "product_df['PCA1'] = product_components[:,0]\n",
        "product_df['PCA2'] = product_components[:,1]\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.scatterplot(data=product_df, x='PCA1', y='PCA2', hue='DBSCAN_Cluster', palette='Set1')\n",
        "plt.title(\"Phân cụm sản phẩm bằng DBSCAN (PCA 2D)\")\n",
        "plt.legend(title='Cụm')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nmpjdV_cRQQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# --- Hàm clustering không tính silhouette, chỉ gán nhãn ---\n",
        "def apply_kmeans(X_scaled, df, n_clusters, label_name):\n",
        "    km = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    labels = km.fit_predict(X_scaled)\n",
        "    df[f\"{label_name}_KMeans\"] = labels\n",
        "\n",
        "def apply_dbscan(X_scaled, df, eps, min_samples, label_name):\n",
        "    db = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "    labels = db.fit_predict(X_scaled)\n",
        "    df[f\"{label_name}_DBSCAN\"] = labels\n",
        "\n",
        "def plot_pca_comparison(X_scaled, df, label_name):\n",
        "    pca = PCA(n_components=2)\n",
        "    pcs = pca.fit_transform(X_scaled)\n",
        "    df_pca = pd.DataFrame(pcs, columns=['PC1','PC2'])\n",
        "    df_pca[label_name+'_KMeans'] = df[f\"{label_name}_KMeans\"].values\n",
        "    df_pca[label_name+'_DBSCAN'] = df[f\"{label_name}_DBSCAN\"].values\n",
        "\n",
        "    fig, axes = plt.subplots(1,2, figsize=(12,5))\n",
        "    sns.scatterplot(ax=axes[0],\n",
        "                    data=df_pca, x='PC1', y='PC2',\n",
        "                    hue=label_name+'_KMeans', palette='tab10', s=40)\n",
        "    axes[0].set_title(f\"{label_name} – KMeans (k=3)\")\n",
        "\n",
        "    sns.scatterplot(ax=axes[1],\n",
        "                    data=df_pca, x='PC1', y='PC2',\n",
        "                    hue=label_name+'_DBSCAN', palette='Set1', s=40)\n",
        "    axes[1].set_title(f\"{label_name} – DBSCAN\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# --- Phân cụm & trực quan hóa cho RFM ---\n",
        "apply_kmeans(rfm_scaled, rfm, n_clusters=3, label_name='RFM')\n",
        "apply_dbscan(rfm_scaled, rfm, eps=0.33, min_samples=4, label_name='RFM')\n",
        "plot_pca_comparison(rfm_scaled, rfm, label_name='RFM')\n",
        "\n",
        "# --- Phân cụm & trực quan hóa cho Product ---\n",
        "apply_kmeans(X_scaled, product_df, n_clusters=3, label_name='Prod')\n",
        "apply_dbscan(X_scaled, product_df, eps=2.5, min_samples=4, label_name='Prod')\n",
        "plot_pca_comparison(X_scaled, product_df, label_name='Prod')\n"
      ],
      "metadata": {
        "id": "2ZITpDcHVan3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}